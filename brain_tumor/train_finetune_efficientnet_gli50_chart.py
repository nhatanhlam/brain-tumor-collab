from fastai.vision.all import *
import timm
import torch
import matplotlib.pyplot as plt
from pathlib import Path
from torch.nn import CrossEntropyLoss
import json
from fastai.data.transforms import IndexSplitter

def safe_save_model(learner, filename, model_dir):
    """LÆ°u mÃ´ hÃ¬nh an toÃ n Ä‘á»ƒ trÃ¡nh lá»—i CUDA khi pickling."""
    device = next(learner.model.parameters()).device
    learner.model.cpu()
    learner.export(model_dir / f"{filename}.pkl")
    learner.model.to(device)

def plot_training_history(train_losses, test_losses, train_accs, test_accs, save_path):
    """Váº½ biá»ƒu Ä‘á»“ Accuracy vÃ  Loss cá»§a Train vÃ  Test."""
    epochs = range(1, len(train_losses) + 1)

    # Accuracy Plot
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, train_accs, label='Train Accuracy', color='blue')
    plt.plot(epochs, test_accs, label='Test Accuracy', color='green')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Model Accuracy')
    plt.legend()
    plt.grid()
    plt.savefig(save_path / "accuracy_plot.png")
    plt.close()

    # Loss Plot
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, train_losses, label='Train Loss', color='blue')
    plt.plot(epochs, test_losses, label='Test Loss', color='green')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Model Loss')
    plt.legend()
    plt.grid()
    plt.savefig(save_path / "loss_plot.png")
    plt.close()

def evaluate_model(learner, test_path):
    """Cháº¡y mÃ´ hÃ¬nh trÃªn táº­p test vÃ  tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng nhÃ£n."""
    test_files = get_image_files(test_path)
    test_dl = learner.dls.test_dl(test_files)
    preds, _ = learner.get_preds(dl=test_dl)
    labels = [learner.dls.vocab[i] for i in preds.argmax(dim=1)]

    true_counts = {label: 0 for label in learner.dls.vocab}
    total_counts = {label: 0 for label in learner.dls.vocab}

    for file, label in zip(test_files, labels):
        actual_label = file.parent.name
        total_counts[actual_label] += 1
        if actual_label == label:
            true_counts[label] += 1

    accuracies = {
        label: (true_counts[label] / total_counts[label] * 100) if total_counts[label] > 0 else 0 
        for label in learner.dls.vocab
    }
    return accuracies

def main():
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c gá»‘c
    base_dir = Path(__file__).resolve().parent
    data_path = base_dir / 'data' / 'Training'
    test_path = base_dir / 'data' / 'Testing'
    model_dir = base_dir / 'models'
    model_dir.mkdir(exist_ok=True)

    required_dirs = ['no_tumor', 'glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']
    if not all((data_path / cls).exists() for cls in required_dirs):
        print(f"âš ï¸ Thiáº¿u thÆ° má»¥c dá»¯ liá»‡u! Kiá»ƒm tra láº¡i: {required_dirs}")
        return

    # Táº¡o DataBlock cho training/validation
    brain_tumor = DataBlock(
        blocks=(ImageBlock, CategoryBlock),
        get_items=get_image_files,
        splitter=RandomSplitter(valid_pct=0.2, seed=42),
        get_y=parent_label,
        item_tfms=Resize(224),
        batch_tfms=aug_transforms(
            do_flip=True, flip_vert=True, max_rotate=40,
            max_zoom=1.4, max_lighting=0.3, max_warp=0.4
        )
    )

    # Load DataLoaders cho training
    dls = brain_tumor.dataloaders(data_path, bs=32, num_workers=0)
    print(f"Sá»‘ áº£nh trong train: {len(dls.train_ds)}, validation: {len(dls.valid_ds)}")

    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh EfficientNet-B3
    learn = vision_learner(dls, "efficientnet_b3", metrics=accuracy, pretrained=True)
    learn.to_fp16()
    learn.model_dir = model_dir

    # Sá»­ dá»¥ng trá»ng sá»‘ cho loss, Æ°u tiÃªn cho glioma
    weights = torch.tensor([1.5, 1.0, 1.0, 1.2]).cuda()
    learn.loss_func = CrossEntropyLoss(weight=weights)

    print("ğŸ”„ Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Fine-Tuning...")

    best_test_acc = 0
    patience = 15
    patience_counter = 0
    epoch = 0
    max_epochs = 200

    train_losses, test_losses = [], []
    train_accs, test_accs = [], []
    log_file = model_dir / "training_log.txt"

    with open(log_file, "w") as log:
        log.write("Epoch | Train Loss | Test Loss | Train Acc | Test Acc\n")
        log.write("-" * 50 + "\n")

        # Táº¡o DataLoader cho táº­p test cÃ³ nhÃ£n báº±ng DataBlock (sá»­ dá»¥ng IndexSplitter([])) Ä‘á»ƒ tÃ­nh test loss
        test_block = DataBlock(
            blocks=(ImageBlock, CategoryBlock),
            get_items=get_image_files,
            splitter=IndexSplitter([]),  # Táº¥t cáº£ áº£nh vÃ o táº­p "train" => labeled
            get_y=parent_label,
            item_tfms=Resize(224)
        )
        test_dls = test_block.dataloaders(test_path, bs=32, num_workers=0)
        test_dl = test_dls.train  # Sá»­ dá»¥ng pháº§n train vÃ¬ chá»©a (input, target)

        while epoch < max_epochs:
            epoch += 1
            print(f"Epoch {epoch} báº¯t Ä‘áº§u...")

            learn.fit_one_cycle(1, 3e-4)

            # 1) Láº¥y train loss tá»« recorder
            train_loss = learn.recorder.losses[-1].item()

            # 2) Láº¥y "val_acc" cÅ© (nhÆ°ng ta khÃ´ng Ä‘á»™ng cháº¡m)
            #    LÆ°u Ã½: learn.recorder.values[-1][1] thá»±c cháº¥t lÃ  validation accuracy
            #    nhÆ°ng ta giá»¯ nguyÃªn tÃªn "train_acc" Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng logic cÅ©
            train_acc = learn.recorder.values[-1][1]

            # 3) TÃ­nh train_acc_real (training accuracy tháº­t sá»±)
            #    => minimal change: ta khÃ´ng in ra console, chá»‰ dÃ¹ng Ä‘á»ƒ váº½
            train_loss_real, train_acc_real = learn.validate(dl=learn.dls[0])
            
            # 4) TÃ­nh test loss + test acc qua validate
            val_results = learn.validate(dl=test_dl)
            test_loss_val = val_results[0]
            test_acc_val = val_results[1]
            test_loss = test_loss_val
            test_acc = test_acc_val.item() if hasattr(test_acc_val, "item") else test_acc_val

            # 5) LÆ°u train_loss thá»±c sá»±, test_loss
            #    + train_acc_real, test_acc => váº½ biá»ƒu Ä‘á»“
            train_losses.append(train_loss_real)  # train_loss_real
            test_losses.append(test_loss)
            train_accs.append(train_acc_real)     # train_acc_real
            test_accs.append(test_acc)

            # 6) In ra console GIá»® NGUYÃŠN logic cÅ© => in Train Loss (tháº­t ra recorder) & Test Acc
            train_loss_str = f"{train_loss:.4f}"
            test_acc_str = f"{test_acc:.4f}"
            print(f"Epoch {epoch} - Train Loss: {train_loss_str}, Test Acc: {test_acc_str}")

            # 7) Ghi log => ta váº«n ghi test_loss (tháº­t) + train_acc (recorder)
            #    Äá»ƒ minimal change, ta giá»¯ "train_acc" cÅ©, test_loss_val váº½ ra
            log.write(f"{epoch:<5} | {train_loss_str} | {test_loss_val:.4f} | {train_acc:.4f} | {test_acc_str}\n")

            if test_acc > best_test_acc:
                best_test_acc = test_acc
                print("ğŸ“¥ LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t...")
                safe_save_model(learn, 'best_model', model_dir)
                patience_counter = 0
            else:
                patience_counter += 1

            if patience_counter >= patience:
                print("â¹ï¸ Dá»«ng training do khÃ´ng cáº£i thiá»‡n liÃªn tiáº¿p.")
                break

    print("ğŸ’¾ LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng...")
    safe_save_model(learn, 'last_model', model_dir)

    # Váº½ biá»ƒu Ä‘á»“ (2 Ä‘Æ°á»ng cho Loss, 2 Ä‘Æ°á»ng cho Accuracy) => do ta Ä‘Ã£ cÃ³ train_losses, test_losses, train_accs, test_accs
    plot_training_history(train_losses, test_losses, train_accs, test_accs, model_dir)

    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn táº­p test
    print("ğŸ” ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn táº­p test...")
    best_model = load_learner(model_dir / "best_model.pkl")
    final_test_acc_dict = evaluate_model(best_model, test_path)

    with open(model_dir / "test_results.json", "w") as f:
        json.dump(final_test_acc_dict, f, indent=4)

    print("âœ… Káº¿t quáº£ test tá»«ng nhÃ£n:")
    for label, acc in final_test_acc_dict.items():
        print(f"ğŸ”¹ {label}: {acc:.2f}%")

if __name__ == '__main__':
    main()
